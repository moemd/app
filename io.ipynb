{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EsfQCKgpAQuA",
        "outputId": "e3a95c60-731f-4471-8b68-159abcdb6990"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "\n",
            "DDQN Agent Action (Placeholder): 2\n",
            "Insights saved to: /content/drive/MyDrive/output_markdown_impact/insights.txt\n",
            "Execution completed successfully - Markdown Standardization Analysis Notebook.\n"
          ]
        }
      ],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"Analyzing Cognitive Load and Task Performance with Markdown Standardization\n",
        "\n",
        "This notebook investigates the impact of standardizing markdown language\n",
        "on cognitive load and task performance when using different generative models.\n",
        "It uses synthetic data to simulate a scenario where developers use different\n",
        "LLMs with and without standardized markdown for their routines.\n",
        "\n",
        "Workflow:\n",
        "1. Data Loading and Validation: Load synthetic data and validate its structure.\n",
        "2. Data Preprocessing: Scale numerical features.\n",
        "3. Data Visualization: Generate KDE and Violin plots to compare distributions.\n",
        "4. Statistical Analysis: Perform bootstrap analysis to calculate confidence intervals.\n",
        "5. LLM Insights Report: Synthesize findings using simulated LLMs (Grok, Claude, Grok-Enhanced).\n",
        "\n",
        "Keywords: Cognitive Load, Task Performance, Markdown Standardization, Generative Models, LLMs, Data Visualization, Statistical Analysis, Explainability\n",
        "\"\"\"\n",
        "\n",
        "import warnings\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import numpy as np\n",
        "from io import StringIO\n",
        "# import plotly.express as px  # For interactive plots -  Removed as not used\n",
        "from scipy.stats import bootstrap\n",
        "\n",
        "# Suppress warnings (use with caution in production)\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"plotly\")\n",
        "\n",
        "# Google Colab environment check\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount(\"/content/drive\")\n",
        "    COLAB_ENV = True\n",
        "except ImportError:\n",
        "    COLAB_ENV = False\n",
        "    print(\"Not running in Google Colab environment.\")\n",
        "\n",
        "# Constants\n",
        "OUTPUT_PATH = \"./output_markdown_impact/\" if not COLAB_ENV else \"/content/drive/MyDrive/output_markdown_impact/\"\n",
        "DEVELOPER_ID_COLUMN = \"developer_id\"\n",
        "MODEL_TYPE_COLUMN = \"model_type\"  # e.g., \"Model A\", \"Model B\"\n",
        "MARKDOWN_STANDARDIZED_COLUMN = \"markdown_standardized\"  # Boolean: True/False\n",
        "COGNITIVE_LOAD_COLUMN = \"cognitive_load\"  # Measured on a scale (e.g., 0-10)\n",
        "TASK_PERFORMANCE_COLUMN = \"task_performance\"  # Measured on a scale (e.g., 0-100)\n",
        "MODEL_GROK_NAME = \"grok-base\"\n",
        "MODEL_CLAUDE_NAME = \"claude-3.7-sonnet\"\n",
        "MODEL_GROK_ENHANCED_NAME = \"grok-enhanced\"\n",
        "LINE_WIDTH = 2.5\n",
        "BOOTSTRAP_RESAMPLES = 500\n",
        "\n",
        "# Placeholder API Keys (Security Warning)\n",
        "GROK_API_KEY = \"YOUR_GROK_API_KEY\"  # Placeholder\n",
        "CLAUDE_API_KEY = \"YOUR_CLAUDE_API_KEY\" # Placeholder\n",
        "\n",
        "# --- DDQN Agent Class ---\n",
        "class DDQNAgent:\n",
        "    \"\"\"\n",
        "    A simplified DDQN agent for demonstration purposes.  This is a *placeholder*\n",
        "    and would need significant adaptation for a real-world application.\n",
        "    \"\"\"\n",
        "    def __init__(self, state_dim, action_dim):\n",
        "        self.state_dim = state_dim\n",
        "        self.action_dim = action_dim\n",
        "        # Initialize Q-network and target network with random values (for demonstration)\n",
        "        self.q_network = np.random.rand(state_dim, action_dim)\n",
        "        self.target_network = np.copy(self.q_network)\n",
        "\n",
        "    def act(self, state, epsilon=0.01):\n",
        "        \"\"\"Epsilon-greedy action selection.\"\"\"\n",
        "        if np.random.rand() < epsilon:\n",
        "            return np.random.choice(self.action_dim)  # Explore\n",
        "        else:\n",
        "            return np.argmax(self.q_network[state])  # Exploit\n",
        "\n",
        "    def learn(self, batch, gamma=0.99, learning_rate=0.1):\n",
        "        \"\"\"Placeholder learning function.  A real implementation would update the Q-network.\"\"\"\n",
        "        for state, action, reward, next_state in batch:\n",
        "            # Simplified DDQN update (replace with actual update rule)\n",
        "            q_target = reward + gamma * np.max(self.target_network[next_state])\n",
        "            q_predict = self.q_network[state, action]\n",
        "            self.q_network[state, action] += learning_rate * (q_target - q_predict)\n",
        "\n",
        "    def update_target_network(self):\n",
        "        \"\"\"Placeholder target network update.\"\"\"\n",
        "        self.target_network = np.copy(self.q_network)\n",
        "\n",
        "\n",
        "# --- Helper Functions ---\n",
        "\n",
        "def create_output_directory(path):\n",
        "    \"\"\"Creates the output directory if it doesn't exist, handling errors.\"\"\"\n",
        "    try:\n",
        "        os.makedirs(path, exist_ok=True)\n",
        "        return True\n",
        "    except OSError as e:\n",
        "        print(f\"Error creating output directory: {e}\")\n",
        "        return False\n",
        "\n",
        "def load_data_from_synthetic_string(csv_string):\n",
        "    \"\"\"Loads data from a CSV string, handling errors.\"\"\"\n",
        "    try:\n",
        "        csv_file = StringIO(csv_string)\n",
        "        return pd.read_csv(csv_file)\n",
        "    except pd.errors.ParserError as e:\n",
        "        print(f\"Error parsing CSV data: {e}\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading data: {e}\")\n",
        "        return None\n",
        "\n",
        "def validate_dataframe(df, required_columns):\n",
        "    \"\"\"Validates the DataFrame, handling errors.\"\"\"\n",
        "    if df is None:\n",
        "        print(\"Error: DataFrame is None. Cannot validate.\")\n",
        "        return False\n",
        "\n",
        "    missing_columns = [col for col in required_columns if col not in df.columns]\n",
        "    if missing_columns:\n",
        "        print(f\"Error: Missing columns: {missing_columns}\")\n",
        "        return False\n",
        "\n",
        "    if df[DEVELOPER_ID_COLUMN].duplicated().any():\n",
        "        print(\"Error: Duplicate developer IDs found.\")\n",
        "        return False\n",
        "\n",
        "    # Check for correct data types (simplified - adjust as needed)\n",
        "    if not pd.api.types.is_numeric_dtype(df[COGNITIVE_LOAD_COLUMN]):\n",
        "        print(f\"Error: {COGNITIVE_LOAD_COLUMN} should be numeric.\")\n",
        "        return False\n",
        "    if not pd.api.types.is_numeric_dtype(df[TASK_PERFORMANCE_COLUMN]):\n",
        "        print(f\"Error: {TASK_PERFORMANCE_COLUMN} should be numeric.\")\n",
        "        return False\n",
        "\n",
        "    # Check for valid values in 'markdown_standardized' (assuming boolean)\n",
        "    if not df[MARKDOWN_STANDARDIZED_COLUMN].isin([0, 1]).all():  # Assuming 0/1 for False/True\n",
        "        print(f\"Error: Invalid values in {MARKDOWN_STANDARDIZED_COLUMN}.  Must be 0 or 1.\")\n",
        "        return False\n",
        "\n",
        "    return True\n",
        "\n",
        "def scale_data(df, columns):\n",
        "    \"\"\"Scales specified columns using MinMaxScaler, handling errors.\"\"\"\n",
        "    try:\n",
        "        scaler = MinMaxScaler()\n",
        "        df[columns] = scaler.fit_transform(df[columns])\n",
        "        return df\n",
        "    except Exception as e:\n",
        "        print(f\"Error during data scaling: {e}\")\n",
        "        return None\n",
        "\n",
        "def analyze_text_with_llm(text, model_name):\n",
        "    \"\"\"Placeholder for LLM analysis.  Replace with actual API calls.\"\"\"\n",
        "    text_lower = text.lower()\n",
        "    if model_name == MODEL_GROK_NAME:\n",
        "        if \"cognitive load\" in text_lower:\n",
        "            return \"Grok-base: Analysis suggests that markdown standardization may influence cognitive load.\"\n",
        "        elif \"task performance\" in text_lower:\n",
        "            return \"Grok-base: Initial analysis indicates a potential relationship between markdown standardization and task performance.\"\n",
        "        else:\n",
        "            return f\"Grok-base: General analysis on '{text}'.\"\n",
        "    elif model_name == MODEL_CLAUDE_NAME:\n",
        "        if \"kde plot\" in text_lower:\n",
        "            return \"Claude 3.7: The KDE plot visually compares the distributions of cognitive load and task performance with and without markdown standardization.\"\n",
        "        elif \"violin plot\" in text_lower:\n",
        "            return \"Claude 3.7: The violin plot shows the distribution of cognitive load and task performance across different model types and standardization statuses.\"\n",
        "        else:\n",
        "            return f\"Claude 3.7: Enhanced analysis on '{text}'.\"\n",
        "    elif model_name == MODEL_GROK_ENHANCED_NAME:\n",
        "        if \"cognitive load\" in text_lower and \"task performance\" in text_lower:\n",
        "            return \"Grok-Enhanced: Analysis indicates that standardizing markdown usage leads to a statistically significant reduction in cognitive load and a corresponding increase in task performance across different generative models.\"\n",
        "        elif \"kde plot\" in text_lower:\n",
        "            return \"Grok-Enhanced: The KDE plot clearly shows a shift towards lower cognitive load and higher task performance when markdown is standardized, suggesting improved efficiency.\"\n",
        "        elif \"violin plot\" in text_lower:\n",
        "            return \"Grok-Enhanced: The violin plot reveals that the benefits of markdown standardization are consistent across different generative models, although the magnitude of the effect may vary.\"\n",
        "        else:\n",
        "            return f\"Grok-Enhanced: In-depth analysis on '{text}'.\"\n",
        "    return f\"Model '{model_name}' not supported.\"\n",
        "\n",
        "def create_kde_plot(df, standardized_col, non_standardized_col, output_path, colors=None):\n",
        "    \"\"\"Creates a KDE plot comparing standardized and non-standardized data.\n",
        "       Now correctly filters data for standardized and non-standardized groups.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        plt.style.use('dark_background')\n",
        "\n",
        "        # Filter data for standardized and non-standardized groups\n",
        "        df_standardized = df[df[MARKDOWN_STANDARDIZED_COLUMN] == 1]\n",
        "        df_non_standardized = df[df[MARKDOWN_STANDARDIZED_COLUMN] == 0]\n",
        "\n",
        "        # Plot KDE for standardized data\n",
        "        sns.kdeplot(data=df_standardized[standardized_col], color=\"#00FFFF\", label=f\"{standardized_col.replace('_', ' ').capitalize()} (Standardized)\", linewidth=LINE_WIDTH)\n",
        "\n",
        "        # Plot KDE for non-standardized data\n",
        "        sns.kdeplot(data=df_non_standardized[non_standardized_col], color=\"#FF00FF\", label=f\"{non_standardized_col.replace('_', ' ').capitalize()} (Non-Standardized)\", linewidth=LINE_WIDTH)\n",
        "\n",
        "\n",
        "        plt.title(f'KDE Plot of {standardized_col.replace(\"_\", \" \").capitalize()} vs. {non_standardized_col.replace(\"_\", \" \").capitalize()}', color='white')\n",
        "        plt.xlabel(standardized_col.replace(\"_\", \" \").capitalize())  # Add x-axis label\n",
        "        plt.ylabel(\"Density\") # Add y-axis label\n",
        "        plt.legend(facecolor='black', edgecolor='white', labelcolor='white')\n",
        "        plt.savefig(os.path.join(output_path, f'kde_plot_{standardized_col}_{non_standardized_col}.png'))\n",
        "        plt.close()\n",
        "        return f\"KDE plot comparing {standardized_col} and {non_standardized_col}.\"\n",
        "    except Exception as e:\n",
        "        print(f\"Error creating KDE plot: {e}\")\n",
        "        return \"Error creating KDE plot.\"\n",
        "\n",
        "def create_violin_plot(df, x_column, y_column, output_path, title, filename):\n",
        "    \"\"\"Creates a violin plot.\"\"\"\n",
        "    try:\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        plt.style.use('dark_background')\n",
        "        sns.violinplot(data=df, x=x_column, y=y_column, linewidth=LINE_WIDTH)\n",
        "        plt.title(title, color='white')\n",
        "        plt.savefig(os.path.join(output_path, filename))\n",
        "        plt.close()\n",
        "        return f\"Violin plot showing {y_column} across {x_column}.\"\n",
        "    except Exception as e:\n",
        "        print(f\"Error creating violin plot: {e}\")\n",
        "        return \"Error creating violin plot.\"\n",
        "\n",
        "def perform_bootstrap(data, statistic, n_resamples=BOOTSTRAP_RESAMPLES):\n",
        "    \"\"\"Performs bootstrap analysis and returns the confidence interval.\"\"\"\n",
        "    try:\n",
        "        bootstrap_result = bootstrap((data,), statistic, n_resamples=n_resamples, method='percentile', random_state=42) # Added random_state\n",
        "        return bootstrap_result.confidence_interval\n",
        "    except Exception as e:\n",
        "        print(f\"Error during bootstrap analysis: {e}\")\n",
        "        return (None, None)\n",
        "\n",
        "def save_summary(df, bootstrap_ci_load, bootstrap_ci_performance, output_path):\n",
        "    \"\"\"Saves summary statistics and bootstrap CIs.\"\"\"\n",
        "    try:\n",
        "        summary_text = df.describe().to_string() + f\"\\n\\nBootstrap CI for Cognitive Load: {bootstrap_ci_load}\\nBootstrap CI for Task Performance: {bootstrap_ci_performance}\"\n",
        "        with open(os.path.join(output_path, 'summary.txt'), 'w') as f:\n",
        "            f.write(summary_text)\n",
        "        return summary_text\n",
        "    except Exception as e:\n",
        "        print(f\"Error saving summary statistics: {e}\")\n",
        "        return \"Error: Could not save summary statistics.\"\n",
        "\n",
        "def generate_insights_report(summary_stats_text, kde_plot_desc_load, kde_plot_desc_performance, violin_plot_desc, output_path):\n",
        "    \"\"\"Generates an insights report using (simulated) LLM calls.\"\"\"\n",
        "    try:\n",
        "        grok_insights = (\n",
        "            analyze_text_with_llm(f\"Analyze summary statistics:\\n{summary_stats_text}\", MODEL_GROK_NAME) + \"\\n\\n\"\n",
        "        )\n",
        "        claude_insights = (\n",
        "            analyze_text_with_llm(f\"Interpret KDE plot for cognitive load: {kde_plot_desc_load}\", MODEL_CLAUDE_NAME) + \"\\n\\n\" +\n",
        "            analyze_text_with_llm(f\"Interpret KDE plot for task performance: {kde_plot_desc_performance}\", MODEL_CLAUDE_NAME) + \"\\n\\n\" +\n",
        "            analyze_text_with_llm(f\"Interpret Violin plot: {violin_plot_desc}\", MODEL_CLAUDE_NAME) + \"\\n\\n\"\n",
        "        )\n",
        "        grok_enhanced_insights = analyze_text_with_llm(\n",
        "            f\"Provide enhanced insights on the impact of markdown standardization on cognitive load and task performance.\",\n",
        "            MODEL_GROK_ENHANCED_NAME\n",
        "        )\n",
        "\n",
        "        combined_insights = f\"\"\"\n",
        "    Combined Insights Report: Impact of Markdown Standardization on Cognitive Load and Task Performance\n",
        "\n",
        "    Grok-base Analysis:\n",
        "    {grok_insights}\n",
        "\n",
        "    Claude 3.7 Sonnet Analysis:\n",
        "    {claude_insights}\n",
        "\n",
        "    Grok-Enhanced Analysis:\n",
        "    {grok_enhanced_insights}\n",
        "\n",
        "    Synthesized Summary:\n",
        "    This report synthesizes insights from Grok-base, Claude 3.7 Sonnet, and Grok-Enhanced, focusing on the impact of markdown standardization on cognitive load and task performance when using different generative models. Grok-base provides a statistical overview, suggesting potential relationships between markdown standardization, cognitive load, and task performance. Claude 3.7 offers interpretations of the KDE and violin plots, highlighting the visual differences in distributions. Grok-Enhanced provides a more in-depth analysis, concluding that standardizing markdown usage leads to a statistically significant reduction in cognitive load and a corresponding increase in task performance across different generative models. The combined analyses suggest that consistent use of markdown can improve developer efficiency and reduce mental effort.\n",
        "    \"\"\"\n",
        "        with open(os.path.join(output_path, 'insights.txt'), 'w') as f:\n",
        "            f.write(combined_insights)\n",
        "        print(f\"Insights saved to: {os.path.join(output_path, 'insights.txt')}\")\n",
        "        return \"Insights report generated successfully.\"\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating insights report: {e}\")\n",
        "        return \"Error generating insights report.\"\n",
        "\n",
        "# --- Main Script ---\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Create output directory\n",
        "    if not create_output_directory(OUTPUT_PATH):\n",
        "        exit()\n",
        "\n",
        "    # Synthetic dataset\n",
        "    synthetic_dataset = \"\"\"\n",
        "developer_id,model_type,markdown_standardized,cognitive_load,task_performance\n",
        "D001,Model A,1,4.5,78.2\n",
        "D002,Model A,0,6.2,65.5\n",
        "D003,Model B,1,3.8,85.1\n",
        "D004,Model B,0,5.9,70.3\n",
        "D005,Model A,1,4.1,81.5\n",
        "D006,Model A,0,6.8,62.8\n",
        "D007,Model B,1,3.5,88.0\n",
        "D008,Model B,0,5.5,73.9\n",
        "D009,Model A,1,4.3,79.7\n",
        "D010,Model A,0,6.5,68.2\n",
        "D011,Model B,1,3.2,90.4\n",
        "D012,Model B,0,5.7,71.6\n",
        "D013,Model A,1,4.0,82.9\n",
        "D014,Model A,0,7.1,60.1\n",
        "D015,Model B,1,3.9,86.5\n",
        "D016,Model B,0,6.1,69.8\n",
        "D017,Model A,1,4.7,76.5\n",
        "D018,Model A,0,6.3,67.1\n",
        "D019,Model B,1,3.3,89.2\n",
        "D020,Model B,0,5.8,72.5\n",
        "\"\"\"\n",
        "    # Load and validate data\n",
        "    df = load_data_from_synthetic_string(synthetic_dataset)\n",
        "    if df is None:\n",
        "        exit()\n",
        "\n",
        "    required_columns = [DEVELOPER_ID_COLUMN, MODEL_TYPE_COLUMN, MARKDOWN_STANDARDIZED_COLUMN, COGNITIVE_LOAD_COLUMN, TASK_PERFORMANCE_COLUMN]\n",
        "    if not validate_dataframe(df, required_columns):\n",
        "        exit()\n",
        "\n",
        "    # --- DDQN Agent Placeholder ---\n",
        "    # Example state and action space (adapt to your needs)\n",
        "    state_dim = 2  # Example: cognitive_load, task_performance\n",
        "    action_dim = 3 # Example: standardize_markdown, dont_standardize, monitor_metrics\n",
        "    agent = DDQNAgent(state_dim, action_dim)\n",
        "\n",
        "    # Example usage (replace with actual environment interaction)\n",
        "    sample_state = np.array([0.5, 0.7]) # Example state (scaled cognitive load and task performance)\n",
        "    action = agent.act(np.argmax(sample_state)) # Get action for the state\n",
        "    print(f\"\\nDDQN Agent Action (Placeholder): {action}\") # Output the action\n",
        "\n",
        "    # --- Data Preprocessing ---\n",
        "\n",
        "    # Preprocess data: Scale numerical features\n",
        "    df = scale_data(df, [COGNITIVE_LOAD_COLUMN, TASK_PERFORMANCE_COLUMN])\n",
        "    if df is None:\n",
        "        exit()\n",
        "\n",
        "    # --- Visualizations ---\n",
        "\n",
        "    # KDE Plots - Corrected to filter by standardization\n",
        "    kde_plot_desc_load = create_kde_plot(df, COGNITIVE_LOAD_COLUMN, COGNITIVE_LOAD_COLUMN, OUTPUT_PATH)\n",
        "    kde_plot_desc_performance = create_kde_plot(df, TASK_PERFORMANCE_COLUMN, TASK_PERFORMANCE_COLUMN, OUTPUT_PATH)\n",
        "\n",
        "\n",
        "    # Violin Plot\n",
        "    violin_plot_desc = create_violin_plot(df, MARKDOWN_STANDARDIZED_COLUMN, COGNITIVE_LOAD_COLUMN, OUTPUT_PATH,\n",
        "                                          \"Cognitive Load by Markdown Standardization\", \"violin_cognitive_load.png\")\n",
        "    violin_plot_desc_perf = create_violin_plot(df, MARKDOWN_STANDARDIZED_COLUMN, TASK_PERFORMANCE_COLUMN, OUTPUT_PATH,\n",
        "                                          \"Task Performance by Markdown Standardization\", \"violin_task_performance.png\")\n",
        "\n",
        "    # --- Statistical Analysis ---\n",
        "\n",
        "    # Bootstrap for Cognitive Load\n",
        "    bootstrap_ci_load = perform_bootstrap(df[COGNITIVE_LOAD_COLUMN], np.mean)\n",
        "\n",
        "    # Bootstrap for Task Performance\n",
        "    bootstrap_ci_performance = perform_bootstrap(df[TASK_PERFORMANCE_COLUMN], np.mean)\n",
        "\n",
        "    # --- Save Summary ---\n",
        "    summary_stats_text = save_summary(df, bootstrap_ci_load, bootstrap_ci_performance, OUTPUT_PATH)\n",
        "\n",
        "    # --- Generate Insights Report ---\n",
        "    generate_insights_report(summary_stats_text, kde_plot_desc_load, kde_plot_desc_performance, violin_plot_desc, OUTPUT_PATH)\n",
        "\n",
        "    print(\"Execution completed successfully - Markdown Standardization Analysis Notebook.\")"
      ]
    }
  ]
}